{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st run through of data with simple models to do data exploration:\n",
    "- linear regression\n",
    "- log regression\n",
    "- log linear\n",
    "\n",
    "Maybe seperate notebook for indepth graph analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#plotting related things \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,  classification_report,  roc_curve, roc_auc_score\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes for no Pam, donor, edit guide: (23347, 21189) (23347, 23315) (23347, 20)\n",
      "RM stack shape (23347, 44524)\n",
      "y label shape (23347,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load arrays for preping DF: \n",
    "\n",
    "For structure of npz:\n",
    "arr one is DNA seq, arr two is label encoding, arr three is one hot \n",
    "\n",
    "Afterwards combine both 1 hot encoding\n",
    "'''\n",
    "RM_noPam = np.load('RM_noPam_Complete_V2.npz')\n",
    "RM_Donor = np.load('RM_donorSeq_Complete_V2.npz')\n",
    "RM_var_edit_guide = np.load('RM_guide_Complete_V2.npz')\n",
    "\n",
    "RM_noPam_onehot =   RM_noPam['arr_2']\n",
    "RM_Donor_onehot = RM_Donor['arr_2']\n",
    "RM_var_edit_guide_onehot = RM_var_edit_guide['arr_2']\n",
    "\n",
    "\n",
    "print('shapes for no Pam, donor, edit guide:',\n",
    "      RM_noPam_onehot.shape, RM_Donor_onehot.shape, RM_var_edit_guide_onehot.shape)\n",
    "\n",
    "#stack arrays via cols\n",
    "RM_stacks = np.column_stack((RM_noPam_onehot, RM_Donor_onehot, RM_var_edit_guide_onehot))\n",
    "Y_labels= np.load('RM_var_DF_V2.npy')\n",
    "print('RM stack shape', RM_stacks.shape)\n",
    "print('y label shape', Y_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of  X_train dataset:  (18677, 44524)\n",
      "Shape of  y_train dataset:  (18677,)\n",
      "Shape of  X_test dataset:  (4670, 44524)\n",
      "Shape of  y_test dataset:  (4670,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trying Smote to address class imbalance \n",
    "\n",
    "'''\n",
    "\n",
    "# Split the data & targets into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(RM_stacks, Y_labels,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Shape of  X_train dataset: \", X_train.shape)\n",
    "print(\"Shape of  y_train dataset: \", y_train.shape)\n",
    "print(\"Shape of  X_test dataset: \", X_test.shape)\n",
    "print(\"Shape of  y_test dataset: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': {} 249\n",
      "Before OverSampling, counts of label '0': {} 18428\n",
      "After OverSampling, the shape of train_X: (36856, 44524)\n",
      "After OverSampling, the shape of train_y: (36856,) \n",
      "\n",
      "After OverSampling, counts of label '1': {} 18428\n",
      "After OverSampling, counts of label '0': {} 18428\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\", (sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {}\", (sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\", (sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\",(sum(y_train_res==0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can adjust parameters -- e.g., change the Cs , make it have class weight, etc  -- but going to start off with a \n",
    "# grid serach \n",
    "#parameters = { 'C': np.linspace(1, 10, 10) }\n",
    "lr = LogisticRegression(C=.01,  verbose=2)\n",
    "#clf = GridSearchCV(lr, parameters, cv=5, verbose=5, n_jobs=3)\n",
    "lr.fit(X_train_res, y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "#np.save('log_regress_y_pred_DATE.npy', y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.94\n",
      "Precision: 0.022026431718061675\n",
      "Recall: 0.08771929824561403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      4613\n",
      "           1       0.02      0.09      0.04        57\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      4670\n",
      "   macro avg       0.51      0.52      0.50      4670\n",
      "weighted avg       0.98      0.94      0.96      4670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, y_test)))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3578d14bb652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't think we can do an ROC curve to look at our data but we can see ! \n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, lr.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lr.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
