{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from collections import OrderedDict\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "#plotting related things \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,  classification_report,  roc_curve, roc_auc_score\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes for alt seq, post guide,  ref: (23397, 81) (23397, 20) (23397, 81)\n",
      "RM stack shape (23397, 182)\n",
      "y label shape (23397,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load arrays for preping DF: \n",
    "\n",
    "For structure of npz:\n",
    "arr one is DNA seq, arr two is label encoding, arr three is one hot \n",
    "\n",
    "Afterwards combine both 1 hot encoding\n",
    "'''\n",
    "RM_alt_seq = np.load('RM_alt_seq_Complete_V3.npz')\n",
    "RM_pos_guide = np.load('RM_pos_guide_Complete_V3.npz')\n",
    "RM_ref_seq = np.load('RM_ref_seq_Complete_V3.npz')\n",
    "\n",
    "RM_alt_seq_onehot =   RM_alt_seq['arr_2']\n",
    "RM_pos_guide_onehot = RM_pos_guide['arr_2']\n",
    "RM_ref_seq_onehot = RM_ref_seq['arr_2']\n",
    "\n",
    "print('shapes for alt seq, post guide,  ref:',\n",
    "      RM_alt_seq_onehot.shape, RM_pos_guide_onehot.shape, RM_ref_seq_onehot.shape)\n",
    "\n",
    "#stack arrays via cols\n",
    "RM_stacks = np.column_stack((RM_alt_seq_onehot, RM_pos_guide_onehot,\n",
    "                             RM_ref_seq_onehot))\n",
    "\n",
    "Y_labels= np.load('RM_var_DF_V3.npy')\n",
    "print('RM stack shape', RM_stacks.shape)\n",
    "print('y label shape', Y_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of  X_train dataset:  (18717, 182)\n",
      "Shape of  y_train dataset:  (18717,)\n",
      "Shape of  X_test dataset:  (4680, 182)\n",
      "Shape of  y_test dataset:  (4680,)\n",
      " train counts of label '1': {} 249\n",
      "train counts of label '0': {} 18468\n",
      " test counts of label '1': {} 57\n",
      "test counts of label '0': {} 4623\n"
     ]
    }
   ],
   "source": [
    "# 3. Split the data & targets into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(RM_stacks, Y_labels,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Shape of  X_train dataset: \", X_train.shape)\n",
    "print(\"Shape of  y_train dataset: \", y_train.shape)\n",
    "print(\"Shape of  X_test dataset: \", X_test.shape)\n",
    "print(\"Shape of  y_test dataset: \", y_test.shape)\n",
    "\n",
    "print(\" train counts of label '1': {}\", (sum(y_train==1)))\n",
    "print(\"train counts of label '0': {}\", (sum(y_train==0)))\n",
    "\n",
    "print(\" test counts of label '1': {}\", (sum(y_test==1)))\n",
    "print(\"test counts of label '0': {}\", (sum(y_test==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with Smote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': {} 249\n",
      "Before OverSampling, counts of label '0': {} 18468\n",
      "After OverSampling, the shape of train_X: (36936, 182)\n",
      "After OverSampling, the shape of train_y: (36936,) \n",
      "\n",
      "After OverSampling, counts of label '1': {} 18468\n",
      "After OverSampling, counts of label '0': {} 18468\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\", (sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {}\", (sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\", (sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\",(sum(y_train_res==0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "rf = RandomForestClassifier()\n",
    "# Train the model on training data\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy ::  0.7634286333116742\n",
      "Test Accuracy  ::  0.8542735042735042\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Accuracy :: \", accuracy_score(y_train_res, rf.predict(X_train_res)))\n",
    "print (\"Test Accuracy  :: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc9744dbda62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model Accuracy: how often is the classifier correct?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Model Precision: what percentage of positive tuples are labeled as such?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Model Recall: what percentage of positive tuples are labelled as such?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred,  normalize=False))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "rf_II = RandomForestClassifier( class_weight= 'balanced')\n",
    "# Train the model on training data\n",
    "rf_II.fit(X_train_res, y_train_res)\n",
    "y_pred_II = rf_II.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8420940170940171\n",
      "Precision: 0.015625\n",
      "Recall: 0.19298245614035087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      4623\n",
      "           1       0.02      0.19      0.03        57\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      4680\n",
      "   macro avg       0.50      0.52      0.47      4680\n",
      "weighted avg       0.98      0.84      0.90      4680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_II))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_II))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_II))\n",
    "print(classification_report(y_test, y_pred_II))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n"
     ]
    }
   ],
   "source": [
    "rf_III =RandomForestClassifier(n_estimators=100, class_weight= 'balanced',\n",
    "                               warm_start=True,  oob_score=True, max_features=\"sqrt\")\n",
    "\n",
    "# Train the model on training data\n",
    "rf_III.fit(X_train_res, y_train_res)\n",
    "y_pred_III = rf_III.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854059829059829\n",
      "Precision: 0.013975155279503106\n",
      "Recall: 0.15789473684210525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      4623\n",
      "           1       0.01      0.16      0.03        57\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      4680\n",
      "   macro avg       0.50      0.51      0.47      4680\n",
      "weighted avg       0.98      0.85      0.91      4680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_III))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_III))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_III))\n",
    "print(classification_report(y_test, y_pred_III))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8542735042735042\n",
      "Precision: 0.015503875968992248\n",
      "Recall: 0.17543859649122806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      4623\n",
      "           1       0.02      0.18      0.03        57\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      4680\n",
      "   macro avg       0.50      0.52      0.47      4680\n",
      "weighted avg       0.98      0.85      0.91      4680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "rf_IV =RandomForestClassifier(n_estimators=10, class_weight= 'balanced',\n",
    "                               warm_start=True,  oob_score=True, max_features=\"sqrt\")\n",
    "\n",
    "# Train the model on training data\n",
    "rf_IV.fit(X_train_res, y_train_res)\n",
    "y_pred_IV = rf_IV.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_IV))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_IV))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_IV))\n",
    "print(classification_report(y_test, y_pred_IV))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:502: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight(\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or \"balanced_subsample\" are '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854059829059829\n",
      "Precision: 0.013975155279503106\n",
      "Recall: 0.15789473684210525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      4623\n",
      "           1       0.01      0.16      0.03        57\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      4680\n",
      "   macro avg       0.50      0.51      0.47      4680\n",
      "weighted avg       0.98      0.85      0.91      4680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_V =RandomForestClassifier(n_estimators=50, class_weight= 'balanced',\n",
    "                               warm_start=True, oob_score=True, max_features=\"sqrt\")\n",
    "\n",
    "# Train the model on training data\n",
    "rf_V.fit(X_train_res, y_train_res)\n",
    "y_pred_V = rf_V.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_V))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_V))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_V))\n",
    "print(classification_report(y_test, y_pred_V))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
