
@article{Ekman1995,
author={Ekman, P.},
title={Strong evidence for universals in facial
expressions: a reply to russell’s mistaken critique},
journal={ACM Trans. Graph. (Proc. SIGGRAPH)},
year={1994}
}



@inproceedings{szegedy2017inception,
  title={Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning.},
  author={C. Szegedy, S. Ioffe, V. Vanhoucke, and A. Alexander},
  booktitle={AAAI},
  pages={4278--4284},
  year={2017}
}
 

@misc{David20147,
  author = {D. Sandberg},
  title = {Face Recognition using Tensorflow},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/davidsandberg/facenet}}
}


@article{Valenza2014,
author={G. Valenza, L. Citi, A. Lanatá, P. Scilingo, and R. Barbieri},
title={Revealing real-time emotional responses: a personalized assessment based on heartbeat dynamics},
journal={Scientific reports},
year={2014}
}


@article{Guo2016,
author={Y. Guo, L. Zhang, Y. Hu, X. He, J and Gao},
title={Ms-celeb-1m: A dataset and benchmark for large-scale face recognition},
journal={In European Conference on Computer Vision},
publisher={Springer International Publishing},
pages={87-102}
year={2016},
}


@article{Yu2015,
author={N. Yu, and F. Chen},
title={Emotion state identification based on heart rate variability and genetic algorithm.},
journal={In Engineering in Medicine and Biology Society (EMBC), 2015 37th Annual International Conference of the IEEE},
year={2015}
}

@article{Abhang2011, 
author={P. Abhang, S. Rao, W. Gawali, and P. Rokade},
title= {Emotion recognition using speech and eeg signal a review},
journal={International  Journal  of  Computer  Applications}, 
volume= {15},
pages={37-40}
year= 2011}

@article{Springenberg2014, 
author={T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller},
title= {Striving for simplicity: The all convolutional net},
journal={International  Journal  of  Computer  Applications}, 
year= 2014}

@article= {Kahou2015, 
authors= {K. Kahou, V. Michalski, K. Konda, R. Memisevic, and C. Pal.},
title= {“Recurrent neural networks for emotion recognition in video},
journal= {ICMI},
pages={467–474},
year=2015}

@article{Ayao2015,
author={A. Yao, J. Shao., N. Ma, and Y. Chen.},
title= {Capturing au-aware facial features and their latent relations for emotion recognition in the wild},
journal= {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, ICMI ’15},
pages= {pp. 451–458}
year=2015}

@article{Ringeval2013},
author = {F. Ringeval, A. Sonderegger, J. Sauer, and D. Lalanne},
title = {Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions. In Automatic Face and Gesture Recognition (FG)},
journal = {10th IEEE International Conference and Workshops},
pages = {1--8}, 
year = 2015
}

@article{Ringeval2014},
author = {F. Ringeval, E. Schuller, E. Kroupi, A. Yuce, J. Thiran, T. Ebrahimi, D. Lalanne, and B. Schuller},
title = {Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data},
journal = {Pattern Recognition Letters},
pages = {22-30}, 
year = 2015
}

@article{Ringeval2015},
author = {F. Ringeval, B. Schuller., M. Valstar, S. Jaiswal, E. Marchi, R. Cowie, and Pantic},
title = {Av+ ec 2015: The first affect
recognition challenge bridging across audio, video,
and physiological data in Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge.},
journal = {ACM},
pages = {234-778}, 
year = 2015
}

@article{Chen2015,
author = {S. Chen, & Q. Jin},
title = {Multi-modal dimensional emotion recognition using recurrent neural networks in Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge.},
journal = {ACM},
volume = 14, 
pages = {234--778}, 
year = 2015
}
@article{He2015
author = { L. He, D. Jiang, L. Yang, E. Pei, P. Wu & H. Sahli},
title = {Multimodal affective dimension prediction using deep bidirectional long short-term memory recurrent neural networks. In Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge},
journal = {ACM},
pages = {73--80}, 
year = 2015
}

@article{Pooya2016,
author = {P. Khorrami, K. Le Paine, C. Brady, T. Dagli, Huang},
title = {How deep neural networks can improve emotion recognition on video data. In Image Processing (ICIP)},
journal = {IEEE}, 
year = 2016
}


@article{Kahou2016,
author = {A. Alpher, J. Fotheringham-Smythe, and G. Gamow},
title = {Emonets: Multimodal deep learning approaches for emotion recognition in video.},
journal = {Journal on Multimodal User Interfaces},
pages = {99--111}, 
year = 2004
}

@article{Ekman1977,
author={Ekman and W. V. Friesen.},
title= {Facial action coding
system.},
year= 1977}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={A. Krizhevsky, I. Sutskever, and G. Hinton},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{hekaming2016imagerecog,
  title={Deep residual learning for image recognition.},
  author={K. He, X. Zhang, R. Shaoqing, and S. Jian},
  journal={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2016},
  publisher={Springer}
}

@article{srivastava2014dropout,
  title={Dropout: A simple way to prevent neural networks from overfitting},
  author={N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{Szegedy2012deeperconvo,
  title={Going deeper with convolutions. },
  author={C. Szegedy, W. Liu, Y. Jia, P. Sermanet, Pierre, S. Reed, D. Anguelov, E. Dumitru, V. Erhna, R. Vincent, A. Rabinovich},
  journal={IEEE Conference on Computer Vision and Pattern Recognition},
  pages= {1-9},
  year={2012},
  publisher={CV- Foundation}
}

@article{Kharat2009_emoNN,
  title={Emotion recognition from facial expression using neural networks.},
  author={G. Kharat, S.V. Dudul},
  journal={n Human-Computer Systems Interaction},
  pages= {207-219},
  year={2009},
  publisher={Springer Berlin Heidelberg.}
}

@article{FerDataset,
  title={Challenges in representation learning:  A report on three machine
learning contests.},
  author={I. J. Goodfellow, D. Erhan, P. L. Carrier, A. Courville, M. Mirza, B. Hamner, W. Cukierski, Y. Tang, D. Thaler, D.-H. Lee, et al.},
  journal={In Neural information processing},
  pages= {117-124},
  year={2013},
  publisher={Springer}
}

@article{VGG2014,
  title={Very deep convolutional networks for large-scale image recognition.},
  author={K. Simonyan and A. Zisserman. },
  journal={arXiv preprint arXiv:1409.1556.},
  year={2014},
}

@article{Conhn2010dataset,
  title={The extended cohn-kanade dataset (ck+):  A complete dataset for  action  unit  and  emotion-specified  expression},
  author={P. Lucey,  J. Cohn,  T. Kanade, J.
Saragih, Z. Ambadar, and I. Matthews},
  journal={CVPRW},
  pages={94-101}
  year={2010},
}

@article{EmoDataset2,
  title={Induced disgust, happiness and surprise:  an addition to the mmi facial ex-
pression database},
  author={M. Valstar and M. Pantic},
  journal={Workshop on EMOTION (satellite of LREC): Corpora for Research on Emotion and Affect},
  pages={65}
  year={2010},
}

@article{Toronto2010,
  title={The  toronto  face  database},
  author={J. Susskind,  A. Anderson, and G. Hinton},
  journal={Department of Computer Science, University of Toronto, Toronto, ON,
Canada, Tech. Rep},
  year={2010},
}

@article{Caifeng_binary2009,
  title={Facial  expression  recognition  based  on  local  binary patterns:  A  comprehensive  study},
  author={S. Caifeng, G. Shaogang, and P. McOwan},
  journal= {Image and Vision Computing},
  volume={27}, year={2009}
}

@article{YuZhang2015_FacialMDL,
  title={Image based static facial expression recognition with multiple deep network learning.},
  author={ Z. Yu and C. Zhang},
  journal= {In Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
  pages = {435–442},
  volume={27}, year={2015}
}

@article{Mengyi_facialexpressionmodel_2013,
  title={Au-aware deep networks for facial expression recognition},
  author={L. Mengyi, L. Shaoxin, S. Shiguang, and X. Chen},
  journal= {FG},
year={2013}, pages={1-6}
}

@article{Guamera2015_ChildernEmoRecg,
  title={Facial expressions and ability to recognize emotions from eyes or mouth in children.},
  author={M. Guarnera, Z. Hichy, I. Cascio, and S. Carrubba},
  journal={Europe's journal of psychology},
  year={2015},}

@article{Liu2014FacialAction,
  title={Deeply learning deformable facial action parts model for
dynamic expression analysis},
  author={M. Liu, S. Li, S. Shan, R. Wang, X. Chen},
  journal={Computer Vision–ACCV 2014},
  pages= {143-157},
  year={2014},
  publisher={ Springer}
}

@article{Tzirakis2017,
author= {P. Tzirakis, G. Trigeorgis, M.A Nicolaou, B. Schuller and S. Zafeiriou},
title= {End-to-End Multimodal Emotion Recognition using Deep Neural Networks. },
journal= {arXiv preprint }

@article{Schroff2015facenet,
author= {F. Schroff, D. Kalenichenko, and J. Philbin},
title= {Facenet: A unified embedding for face recognition and clustering.}
journal= {IEEE}, 
pages= {815-823},
year= 2015}

@inproceedings{BarsoumICMI2016,
    title={Training Deep Networks for Facial Expression Recognition with Crowd-Sourced Label Distribution},
    author={E. Barsoum, C. Zhang and F. Canton, F. Cristian and Z. Zhengyou},
    booktitle={ACM International Conference on Multimodal Interaction (ICMI)},
    year={2016}
}

@article{Kolakowska2014, 
author={A. Kołakowska, A. Landowska, M. Szwoch, W. Szwoch, and
M. R. Wrobel}, 
title= {Human-Computer Systems Interaction: Backgrounds
and Applications 3, ch. Emotion Recognition and Its
Applications}, page={51–62}, publisher={} Cham: Springer International Publishing}, year=2014}


@article{Yu2015, author={Z. Yu and C. Zhang}, title={“Image based static facial expression recognition with multiple deep network learning}, publisher={Proceedings
of the 2015 ACM on International Conference on
Multimodal Interaction, ICMI}, pages={435-442}, year= 2015
}